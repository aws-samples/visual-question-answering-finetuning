{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637f7985",
   "metadata": {},
   "source": [
    "# Finetune and Deploy BLIP-2 with Amazon SageMaker for Visual Question Answering\n",
    "\n",
    "In this notebook, we are going to fine-tune BLIP-2 for visual question answering. This will be used for a fashion product description generation use case.\n",
    "\n",
    "In our example, we are going to leverage Hugging Face [Transformers](https://huggingface.co/docs/transformers/index) and [PEFT](https://github.com/huggingface/peft) for the finetuning.\n",
    "\n",
    "## 1. Setup development environment\n",
    "\n",
    "Select the `Data Science 3.0` Image with `ml.t3.medium` instance type\n",
    "\n",
    "Please make sure the IAM Role being used has the following permissions:\n",
    "  - S3 Bucket access\n",
    "  - SageMaker access\n",
    "\n",
    "You can use the following IAM policy:\n",
    " - `arn:aws:iam::aws:policy/AmazonS3FullAccess`\n",
    " - `arn:aws:iam::aws:policy/AmazonSageMakerFullAcces`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1bce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q --upgrade \"scikit-image\" \"sagemaker>=2.190.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de19fc",
   "metadata": {},
   "source": [
    "Here we set up the default session and bucket to use. If you want to use a different bucket, you can replace the bucket with the preferred bucket name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa71bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_session_bucket = None\n",
    "\n",
    "if sagemaker_session_bucket is None and sagemaker_session is not None:\n",
    "    # set to default bucket if a bucket name is not given, sagemaker will automatically create this bucket if it not exists\n",
    "    sagemaker_session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sagemaker_session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451216e",
   "metadata": {},
   "source": [
    "## 2. Load and prepare data\n",
    "\n",
    "For the following demo we will be using tha Kaggle [Fashion Product Images Dataset](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset). We will use the shirt category `Tshirts` and `Shirts` as an example to finetune the model. The main files in the data sets are\n",
    "1. `styles.csv`: all products and some of their key categories. We use this file to filter on the products that we're interested in.\n",
    "2. `images.csv`: the link to all the images.\n",
    "3. `images/product_id.jpg`: image of the product of id `product_id`.\n",
    "4. `styles/product_id.json`: complete metadata of the product of id `product_id`.\n",
    "\n",
    "\n",
    "#### You have to follow the following steps to load the data:\n",
    "1. Sign in to Kaggle and download the dataset\n",
    "2. Unzip the dataset and move the dataset into the folder `data`\n",
    "\n",
    "For the following preprocessing code to work, the following structure is expected:\n",
    "- `data/styles.csv`\n",
    "- `data/images.csv`\n",
    "- `data/styles/`\n",
    "- `data/images/`\n",
    "\n",
    "In the following processing, we perform two steps to create the train and test dataset.\n",
    "1. Extract all the attributes from the product JSON file to create one CSV file containing information of all products and their attributes of interest. This can be used for data exploration.\n",
    "2. Format the train and test dataset by \n",
    "\n",
    "### Combine all JSON attribute files into one dataset and filter the ids based on image availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc00bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_summary = pd.read_csv('../data/images.csv')\n",
    "attr_summary = pd.read_csv('../data/styles.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10caa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that some images don't have a link so we should remove them from the dataset\n",
    "undefined_images = image_summary[image_summary.link == 'undefined']\n",
    "undefined_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9eb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove these records from the attribute summary\n",
    "undefined_images_id = undefined_images.filename.apply(lambda x: x.replace('.jpg', '')).values\n",
    "attr_summary['id'] = attr_summary['id'].astype(str)\n",
    "attr_summary = attr_summary[~attr_summary.id.isin(undefined_images_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the target shirt for finetuning\n",
    "tops = attr_summary[attr_summary['articleType'].isin(['Shirts', 'Tshirts'])]\n",
    "tops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "\n",
    "for id in tqdm(tops['id']):\n",
    "    with open(f\"../data/styles/{id}.json\", \"r\") as f:\n",
    "        fl = f.read()\n",
    "        jsn = json.loads(fl)\n",
    "\n",
    "    attr = jsn['data']['articleAttributes']\n",
    "    descr = jsn['data']['productDescriptors']\n",
    "    \n",
    "    attr.update(descr)\n",
    "    attr['id'] = id\n",
    "    attr['baseColour'] = tops\n",
    "    row_df = pd.json_normalize(attr, sep='_')\n",
    "    \n",
    "    dataset = pd.concat([dataset, row_df], ignore_index=True)\n",
    "    \n",
    "    \n",
    "# also add color to the dataset\n",
    "dataset['id'] = dataset['id'].astype(str)\n",
    "dataset = dataset.merge(tops[['id', 'baseColour']], on='id')\n",
    "\n",
    "dataset.to_csv(\"../data/dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c183ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Fit', 'Pattern', 'Body or Garment Size', 'Sleeve Length',\n",
       "       'Fabric', 'Collar', 'id', 'description_descriptorType',\n",
       "       'description_value', 'Occasion', 'Fabric 2', 'Fabric 3', 'Neck',\n",
       "       'materials_care_desc_descriptorType', 'materials_care_desc_value',\n",
       "       'size_fit_desc_descriptorType', 'size_fit_desc_value',\n",
       "       'style_note_descriptorType', 'style_note_value', 'Sleeve Styling',\n",
       "       'Business Unit', 'Multipack Set', 'Main Trend', 'Print or Pattern Type',\n",
       "       'Number of Components', 'Sport Team', 'Segment', 'Sport', 'Technology',\n",
       "       'Players', 'Character', 'Wash Care', 'Number of Pockets',\n",
       "       'Surface Styling', 'Length', 'Brick', 'Family', 'Class',\n",
       "       'Pattern Coverage', 'Processing Time', 'Brand Fit Name', 'Plating',\n",
       "       'Hemline', 'Placket', 'Placket Length', 'Transparency', 'Pocket Type',\n",
       "       'Weave Pattern', 'Cuff', 'Stitch', 'Brand', 'Colour Shade Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3ca0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formulate questions and answers for finetuning\n",
    "cols = [\"id\", \"Fabric\", \"Fit\", \"Collar\", \"Pattern\", \"Sleeve Length\", \"Sleeve Styling\", \"Neck\", \"baseColour\"]\n",
    "dataset = dataset[cols]\n",
    "\n",
    "product_attributes = [\n",
    "    {\n",
    "        \"Attribute\": \"Fabric\",\n",
    "        \"Prompt\": \"What is the fabric of the shirt in this picture?\",\n",
    "    },\n",
    "    {\n",
    "        \"Attribute\": \"Fit\",\n",
    "        \"Prompt\": \"What is the Fit of the shirt in this picture?\",\n",
    "    },\n",
    "    {\n",
    "        \"Attribute\": \"Collar\",\n",
    "        \"Prompt\": \"What is the collar of the shirt in this picture?\",\n",
    "    },\n",
    "    {\n",
    "        \"Attribute\": \"Pattern\",\n",
    "        \"Prompt\": \"What is the pattern of the shirt in this picture?\",\n",
    "    },\n",
    "    {\n",
    "        \"Attribute\": \"Neck\",\n",
    "        \"Prompt\": \"What is the neck type of the shirt in this picture?\",\n",
    "    },\n",
    "    {\n",
    "        \"Attribute\": \"Sleeve Length\",\n",
    "        \"Prompt\": \"What is the sleeve length of the shirt in this picture?\",\n",
    "    },\n",
    "    {\n",
    "        \"Attribute\": \"Sleeve Styling\",\n",
    "        \"Prompt\": \"What is the sleeve styling of the shirt in this picture?\",\n",
    "    },\n",
    "    {\n",
    "        \"Attribute\": \"baseColour\",\n",
    "        \"Prompt\": \"What is the colour of the shirt in this picture?\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fdbccfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_data = []\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    for attribute in product_attributes:\n",
    "        if row[attribute['Attribute']] is not np.nan:\n",
    "            item_data = {}\n",
    "            item_data['id'] = row['id']\n",
    "            item_data['Question'] = attribute['Prompt'] \n",
    "            item_data['Answer'] = f\"{attribute['Attribute']}: {row[attribute['Attribute']]}\"\n",
    "            vqa_data.append(item_data)\n",
    "\n",
    "vqa = pd.DataFrame.from_records(vqa_data)\n",
    "print(vqa.shape)\n",
    "vqa.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd72bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = vqa.groupby(\"id\").sample(frac=0.8,random_state=200)\n",
    "test = vqa.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb88194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dont want to finetune on colour, however we want to extract colour during testing/inference\n",
    "print(train.shape[0])\n",
    "train = train[train['Question'] != \"What is the colour of the shirt in this picture?\"]\n",
    "print(train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a748dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44385</th>\n",
       "      <td>38642</td>\n",
       "      <td>What is the fabric of the clothing in this pic...</td>\n",
       "      <td>Fabric: Cotton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           Question  \\\n",
       "44385  38642  What is the fabric of the clothing in this pic...   \n",
       "\n",
       "               Answer  \n",
       "44385  Fabric: Cotton  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9db2d2",
   "metadata": {},
   "source": [
    "### Upload data to S3 for the finetuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "645b0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload train and test sets\n",
    "train.to_csv(f\"s3://{sagemaker_session_bucket}/data/vqa_train.csv\", index=False)\n",
    "test.to_csv(f\"s3://{sagemaker_session_bucket}/data/vqa_test.csv\", index=False)\n",
    "\n",
    "# upload images to S3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "for id in tqdm(tops['id']):\n",
    "    s3_client.upload_file(f'/data/images/{id}.jpg', sagemaker_session_bucket, f'/data/images/{id}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e6513",
   "metadata": {},
   "source": [
    "## 3. Fine-Tune BLIP-2 with LoRA on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "367fc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify inputs to Training Jobs\n",
    "inputs = f\"s3://{sagemaker_session_bucket}/data/\"\n",
    "image_s3_uri = f\"s3://{sagemaker_session_bucket}/data/images\"\n",
    "output_path = f\"s3://{sagemaker_session_bucket}/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f2a8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "input_file = TrainingInput(s3_data=inputs, input_mode=\"File\")\n",
    "images_input = TrainingInput(s3_data=image_s3_uri, input_mode=\"FastFile\", content_type=\"application/jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ed529abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: VQA-2024-02-07-13-03-54-497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-07 13:03:55 Starting - Starting the training job...\n",
      "2024-02-07 13:03:58 Pending - Training job waiting for capacity......\n",
      "2024-02-07 13:05:07 Pending - Preparing the instances for training......\n",
      "2024-02-07 13:06:14 Downloading - Downloading input data...................................................\n",
      "2024-02-07 13:14:52 Training - Training image download completed. Training in progress.bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-02-07 13:14:54,024 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-02-07 13:14:54,044 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-02-07 13:14:54,053 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-02-07 13:14:54,057 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-02-07 13:14:54,258 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.9 -m pip install -r requirements.txt\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (9.4.0)\n",
      "Collecting transformers>=4.31.0\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 75.3 MB/s eta 0:00:00\n",
      "Collecting peft==0.5.0\n",
      "Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 21.3 MB/s eta 0:00:00\n",
      "Collecting accelerate==0.21.0\n",
      "Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 244.2/244.2 kB 35.9 MB/s eta 0:00:00\n",
      "Collecting bitsandbytes==0.40.2\n",
      "Downloading bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.5/92.5 MB 15.8 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.3.3\n",
      "Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 76.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 3)) (4.64.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 3)) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 3)) (1.13.1+cu117)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 3)) (23.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from peft==0.5.0->-r requirements.txt (line 3)) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers>=4.31.0->-r requirements.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.31.0->-r requirements.txt (line 2)) (2022.10.31)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "Downloading tokenizers-0.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 78.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers>=4.31.0->-r requirements.txt (line 2)) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 330.1/330.1 kB 48.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.31.0->-r requirements.txt (line 2)) (4.4.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.9/170.9 kB 34.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 2)) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 2)) (2.1.1)\n",
      "Installing collected packages: bitsandbytes, safetensors, fsspec, huggingface-hub, accelerate, tokenizers, transformers, peft\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2023.1.0\n",
      "Uninstalling fsspec-2023.1.0:\n",
      "Successfully uninstalled fsspec-2023.1.0\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface-hub 0.12.0\n",
      "Uninstalling huggingface-hub-0.12.0:\n",
      "Successfully uninstalled huggingface-hub-0.12.0\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.16.0\n",
      "Uninstalling accelerate-0.16.0:\n",
      "Successfully uninstalled accelerate-0.16.0\n",
      "Attempting uninstall: tokenizers\n",
      "Found existing installation: tokenizers 0.13.2\n",
      "Uninstalling tokenizers-0.13.2:\n",
      "Successfully uninstalled tokenizers-0.13.2\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.26.0\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "hyperparameters = {\n",
    "    'epochs': 10,\n",
    "    'file-name': \"vqa_train.csv\",\n",
    "}\n",
    "\n",
    "estimator = HuggingFace(\n",
    "    entry_point=\"entrypoint_vqa_finetuning.py\",\n",
    "    source_dir=\"../src\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\", \n",
    "    transformers_version='4.26',\n",
    "    pytorch_version='1.13',\n",
    "    py_version='py39',\n",
    "    hyperparameters = hyperparameters,\n",
    "    base_job_name=\"VQA\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=f\"{output_path}/models\",\n",
    "    code_location=f\"{output_path}/code\",\n",
    "    volume_size=60,\n",
    "    metric_definitions=[\n",
    "        {'Name': 'batch_loss', 'Regex': 'Loss: ([0-9\\\\.]+)'},\n",
    "        {'Name': 'epoch_loss', 'Regex': 'Epoch Loss: ([0-9\\\\.]+)'}\n",
    "    ],\n",
    ")\n",
    "\n",
    "estimator.fit({\"images\": images_input, \"input_file\": input_file})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1667841",
   "metadata": {},
   "source": [
    "## 4. Deploy Fine-tuned BLIP-2 on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39331645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "model = HuggingFaceModel(\n",
    "   model_data=estimator.model_data,\n",
    "   role=role, \n",
    "   transformers_version=\"4.28\", \n",
    "   pytorch_version=\"2.0\", \n",
    "   py_version=\"py310\",\n",
    "   model_server_workers=1,\n",
    "   sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7a91a640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-inference-2024-02-07-12-45-48-758\n",
      "INFO:sagemaker:Creating endpoint-config with name endpoint-finetuned-blip2-final\n",
      "INFO:sagemaker:Creating endpoint with name endpoint-finetuned-blip2-final\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.huggingface.model.HuggingFacePredictor at 0x168a36e50>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = \"endpoint-finetuned-blip2\"\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf741f",
   "metadata": {},
   "source": [
    "## 5. Run inference on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e84120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample one test image\n",
    "sample_image_id = test.sample(1)['id'].values[0]\n",
    "test_image = f\"../data/{sample_image_id}.jpg\"\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "144a4f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sleeve Length: Long Sleeves'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import re \n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "def encode_image(img_file):\n",
    "    with open(img_file, \"rb\") as image_file:\n",
    "        img_str = base64.b64encode(image_file.read())\n",
    "        base64_string = img_str.decode(\"latin1\")\n",
    "    return base64_string\n",
    "\n",
    "def run_inference(endpoint_name, inputs):\n",
    "    response = smr_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, Body=json.dumps(inputs),  ContentType=\"application/json\"\n",
    "    )\n",
    "    return response[\"Body\"].read().decode(\"utf-8\")\n",
    "    \n",
    "base64_string = encode_image(test_image)\n",
    "\n",
    "\n",
    "attributes = []\n",
    "\n",
    "for product_attribute in product_attributes:\n",
    "    inputs = {\n",
    "        \"prompt\": f\"Question: {product_attribute['Prompt']} Answer: \",\n",
    "        \"image\": base64_string\n",
    "    }\n",
    "    response = run_inference(endpoint_name, inputs)\n",
    "    attributes.append(re.sub(\"[\\\"']\", \"\", response))\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f70a0",
   "metadata": {},
   "source": [
    "## 6. Generate product description with Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a4206ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert in writing product descriptions for shirts. Use the data below to create product description for a website. \n",
      "The product description should contain all given attributes.\n",
      "Provide some inspirational sentences, on e.g. how the fabric moves. Think about what a potential customer wants to know about the shirts. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an expert in writing product descriptions for shirts. Use the data below to create product description for a website. \n",
    "The product description should contain all given attributes.\n",
    "Provide some inspirational sentences, on e.g. how the fabric moves. Think about what a potential customer wants to know about the shirts. \n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0958a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_content =  {\"role\": \"user\", \"content\": f\"Here are the facts you need to create the product descriptions: <product_attributes>{', '.join(attributes)}</product_attributes>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52d18130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic Striped Shirt Relax into comfortable casual style with this classic collared striped shirt. With a regular fit that is neither too slim nor too loose, this versatile top layers perfectly under sweaters or jackets.\n"
     ]
    }
   ],
   "source": [
    "bedrock = boto3.client(    \n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2',\n",
    ")\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "body = json.dumps({\n",
    "    \"system\":prompt,\n",
    "    \"messages\": [attributes_content],\n",
    "    \"max_tokens\": 400,\n",
    "    \"temperature\": 0.1,\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "})\n",
    "\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock.invoke_model(\n",
    "     body=body,\n",
    "     modelId=model_id,\n",
    "     accept=accept,\n",
    "     contentType=contentType\n",
    " )\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7272cec",
   "metadata": {},
   "source": [
    "## 7. Delete resources\n",
    "\n",
    "Delete the SageMaker endpoint and the endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "\n",
    "response = client.delete_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "\n",
    "response = client.delete_endpoint_config(\n",
    "    EndpointConfigName=endpoint_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
